{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from collections import defaultdict\n",
    "\n",
    "W = LinearSegmentedColormap.from_list('w', [\"w\", \"w\"], N=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIONS = {\n",
    "    0: [1, 0],   \n",
    "    1: [-1, 0],  \n",
    "    2: [0, -1],  \n",
    "    3: [0, 1],}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ACTUAL STATE VALUES FROM DYNAMIC PROGRAMMING\n",
    "# [[  0. -14. -20. -22.]\n",
    "#  [-14. -18. -20. -20.]\n",
    "#  [-20. -20. -18. -14.]\n",
    "#  [-22. -20. -14.   0.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorld:\n",
    "    def __init__(self, size=4):\n",
    "\n",
    "        self.size = size\n",
    "        self.state_value = np.zeros((self.size,self.size))\n",
    "        self.feature_size = 4\n",
    "        self.state_space_size = self.size*self.size\n",
    "        self.real_size = self.size -1\n",
    "        \n",
    "        # self.w = np.ones((self.state_space_size,self.feature_size))\n",
    "        # self.feature = np.ones((self.state_space_size,self.feature_size))\n",
    "\n",
    "        #Features = [Direction From 3 - X Axis, Direction From 3 - Y Axis,Direction From 0 - X Axis, Direction From 0 - Y Axis,Current X, Current Y]\n",
    "        self.features = defaultdict(lambda: np.zeros(self.feature_size))\n",
    "        self.w = defaultdict(lambda: np.zeros(self.feature_size))\n",
    "        self.alpha = 0.001\n",
    "        self.discount = 1\n",
    "        return\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        # self.state_value = np.zeros((self.size, self.size))\n",
    "        x = np.random.randint(self.size)\n",
    "        y = np.random.randint(self.size)\n",
    "\n",
    "        state = (x,y)\n",
    "    \n",
    "        return state\n",
    "\n",
    "    def step(self, state, action):\n",
    "        done = False\n",
    "        # is terminal state?\n",
    "        size = len(self.state_value) - 1\n",
    "        if (state == (0, 0)) or (state == (size, size)):\n",
    "            done = True\n",
    "            return state, 0,done\n",
    "\n",
    "        s_1 = (state[0] + action[0], state[1] + action[1])\n",
    "        reward = -1\n",
    "        # out of bounds north-south\n",
    "        if s_1[0] < 0 or s_1[0] >= len(self.state_value):\n",
    "            s_1 = state\n",
    "        # out of bounds east-west\n",
    "        elif s_1[1] < 0 or s_1[1] >= len(self.state_value):\n",
    "            s_1 = state\n",
    "\n",
    "        return s_1, reward,done\n",
    "\n",
    "    def get_action(self):\n",
    "\n",
    "        _action_ = np.random.randint(4)\n",
    "        action = ACTIONS.get(_action_)\n",
    "\n",
    "        return action\n",
    "\n",
    "    def TD_Semi_Gradient(self):\n",
    "    #Features = [Direction From 3 - X Axis, Direction From 3 - Y Axis,Direction From 0 - X Axis, Direction From 0 - Y Axis,Current X, Current Y]\n",
    "        \n",
    "        state = self.reset()\n",
    "\n",
    "        while True:\n",
    "\n",
    "            action = self.get_action()\n",
    "\n",
    "            next_state,reward,done = self.step(state,action)\n",
    "\n",
    "            self.features[state] = [self.real_size-state[0],self.real_size-state[1],state[0],state[1]]\n",
    "\n",
    "            f_arr_s = np.array(self.features[state])\n",
    "            w_arr_s = np.array(self.w[state])\n",
    "\n",
    "            f_arr_n_s = np.array(self.features[next_state])\n",
    "            w_arr_n_s = np.array(self.w[next_state])\n",
    "\n",
    "\n",
    "            Value_State = np.dot(w_arr_s,f_arr_s)\n",
    "            Value_Next_State = np.dot(w_arr_n_s,f_arr_n_s)\n",
    "\n",
    "            if done:\n",
    "                Value_Next_State = 0\n",
    "\n",
    "            for i,real_feature in enumerate(self.features[state]):\n",
    "\n",
    "                self.w[state][i] += self.alpha*(reward + self.discount*(Value_Next_State) - Value_State)*self.features[state][i]\n",
    "\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "            state = next_state\n",
    "\n",
    "\n",
    "        return self.w,self.features\n",
    "\n",
    "    def loop(self):\n",
    "\n",
    "\n",
    "        for x in range(200000):\n",
    "\n",
    "            print(\"Predicting State Values:  {:.5f}\".format(x), end=\"\\r\")\n",
    "            self.w,self.features = self.TD_Semi_Gradient()\n",
    "\n",
    "\n",
    "        return self.w,self.features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = GridWorld()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ""
     ]
    }
   ],
   "source": [
    "w,f = env.loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0. 0. 0. 0.]\n [0. 0. 0. 0.]\n [0. 0. 0. 0.]\n [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "state_value = np.zeros((env.size,env.size))\n",
    "print('\\n Initial State Values...')\n",
    "print(state_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "for state in f:\n",
    "    # print(f[state])\n",
    "    f_arr = np.array(f[state])\n",
    "    w_arr = np.array(w[state])\n",
    "    # print(w_arr)\n",
    "\n",
    "    val = np.dot(w_arr,f_arr)\n",
    "    state_value[state] = val\n",
    "    # print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 0.         -0.14131167 -0.17341443 -0.22998722]\n [-0.26280871 -0.21691602 -0.17830402 -0.17847296]\n [-0.36078248 -0.22314004 -0.20596619 -0.11559938]\n [-0.38646545 -0.19688949 -0.25490022  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print('\\n')\n",
    "print('Final State Values...')\n",
    "print(state_value)"
   ]
  }
 ]
}