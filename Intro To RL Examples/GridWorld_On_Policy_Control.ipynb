{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "W = LinearSegmentedColormap.from_list('w', [\"w\", \"w\"], N=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Starting State = (1/0)\n",
    "#Terminal State = (2,3)\n",
    "\n",
    "Move_Reward = -1\n",
    "Final_Reward = 10\n",
    "\n",
    "ACTIONS = {\n",
    "    0: [1, 0],   # north\n",
    "    1: [-1, 0],  # south\n",
    "    2: [0, -1],  # west\n",
    "    3: [0, 1],   # east\n",
    "}\n",
    "discount = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorld:\n",
    "    \n",
    "    def __init__(self,size = 4,iters= 1):\n",
    "        \n",
    "        self.Q = defaultdict(lambda: np.zeros(4))\n",
    "        self.size = size\n",
    "        self.iters = iters\n",
    "        self.eps = 1\n",
    "        self.eps_decay = 0.9999997\n",
    "        self.eps_min = 0.05\n",
    "        self.N = defaultdict(lambda: np.zeros(4))\n",
    "        self.Returns = defaultdict(lambda: np.zeros(4))\n",
    "    \n",
    "    #Get Starting State\n",
    "    def reset(self):\n",
    "        state = (1,0)\n",
    "        return state\n",
    "        \n",
    "    #Perform Action\n",
    "    def step(self,state,action):\n",
    "        \n",
    "        done = False\n",
    "        \n",
    "        if state == (self.size-2,self.size-1):\n",
    "            reward = Final_Reward\n",
    "            done = True\n",
    "            return state,reward,done\n",
    "        s_1 = (state[0]+action[0],state[1]+action[1])\n",
    "        reward = Move_Reward\n",
    "        \n",
    "        if s_1[0]<0 or s_1[0]>=(self.size):\n",
    "            s_1 = state\n",
    "            \n",
    "        if s_1[1]<0 or s_1[1]>=(self.size):\n",
    "            s_1 = state\n",
    "            \n",
    "        return s_1,reward,done\n",
    "    \n",
    "    #Get the probablity of every action/ Depends upon the value epsilon which decays through time\n",
    "    def get_action_prob(self,Q_S):\n",
    "        \n",
    "        action_probs = np.ones(len(ACTIONS))*(self.eps/len(ACTIONS))\n",
    "        best_action = np.argmax(Q_S)\n",
    "        action_probs[best_action] = (1-self.eps) + self.eps/len(ACTIONS)\n",
    "        return action_probs\n",
    "        \n",
    "    #Select the best action\n",
    "    def best_policy(self):\n",
    "        \n",
    "        return dict((state,np.argmax(action))for state,action in self.Q.items())\n",
    "    \n",
    "    #Generate random episdoe for the agent to learn upon\n",
    "    def get_episode(self):\n",
    "        \n",
    "        trajectory = []\n",
    "        \n",
    "        state = self.reset()\n",
    "        \n",
    "        while True:\n",
    "            #Getting the action\n",
    "            action_probs = self.get_action_prob(self.Q[state])\n",
    "            action_to_select = np.random.choice(np.arange(len(ACTIONS)),p = action_probs) if state in self.Q else np.random.randint(0,4) \n",
    "            action = ACTIONS.get(action_to_select)\n",
    "            \n",
    "            next_state,reward,done = self.step(state,action)\n",
    "            trajectory.append((state,action,reward))\n",
    "            state = next_state\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "                \n",
    "        return trajectory \n",
    "    \n",
    "    #Update the state_action_values \n",
    "    def update_Q(self):\n",
    "        \n",
    "        tra = self.get_episode()\n",
    "        states,actions,rewards = zip(*tra)\n",
    "        #print(tra)\n",
    "        \n",
    "        for i,state in enumerate(states):\n",
    "            \n",
    "            if actions[i] == [1, 0]:\n",
    "                a = 0\n",
    "            elif actions[i] == [-1,0]:\n",
    "                a = 1\n",
    "            elif actions[i] == [0,-1]:\n",
    "                a = 2\n",
    "            elif actions[i] == [0,1]:\n",
    "                a = 3\n",
    "            \n",
    "            self.N[state][a] += 1\n",
    "            alpha = 1/self.N[state][a]\n",
    "            self.Q[state][a] += alpha*(sum(rewards[i:])-self.Q[state][a])\n",
    "        \n",
    "        return self.Q\n",
    "    \n",
    "    #Main Loop calling update_Q and decaying Epsilon \n",
    "    def Monte_Carlo_On_Policy(self):\n",
    "        \n",
    "        for i in range(self.iters):\n",
    "            \n",
    "            if i % 5 == 0:\n",
    "                print(\"In Loop {:.5f}\".format(i), end=\"\\r\")\n",
    "            \n",
    "            self.eps = max(self.eps_min,self.eps_decay*self.eps)\n",
    "\n",
    "            self.Q = self.update_Q()\n",
    "            \n",
    "        policy = self.best_policy()\n",
    "        \n",
    "        return self.Q,policy\n",
    "        \n",
    "    #Selecting the best_value function\n",
    "    def best_value(self):\n",
    "        \n",
    "        return dict((state,np.max(action))for state,action in self.Q.items())\n",
    "    \n",
    "    def render(self,values_matrix, title=None):\n",
    "\n",
    "        size = len(values_matrix) if len(values_matrix) < 20 else 20\n",
    "        fig, ax = plt.subplots(figsize=(size, size))\n",
    "        if title is not None:ax.set_title(title)\n",
    "        ax.grid(which='major', axis='both',linestyle='-', color='k', linewidth=2)\n",
    "        sn.heatmap(values_matrix, annot=True, fmt=\".1f\", cmap=W,linewidths=1, linecolor=\"black\", cbar=False)\n",
    "        plt.show()\n",
    "        return fig, ax\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Loop 199995.00000\r"
     ]
    }
   ],
   "source": [
    "iters = 200000\n",
    "env = GridWorld(4,iters)\n",
    "\n",
    "Q,policy = env.Monte_Carlo_On_Policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = env.best_value() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 0): 3,\n",
       " (1, 1): 3,\n",
       " (2, 0): 3,\n",
       " (3, 0): 3,\n",
       " (2, 1): 3,\n",
       " (3, 1): 3,\n",
       " (3, 2): 3,\n",
       " (2, 2): 3,\n",
       " (1, 2): 3,\n",
       " (1, 3): 0,\n",
       " (0, 2): 3,\n",
       " (0, 1): 3,\n",
       " (0, 0): 3,\n",
       " (2, 3): 0,\n",
       " (0, 3): 0,\n",
       " (3, 3): 1}"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.GridWorld.__init__.<locals>.<lambda>()>,\n",
       "            {(1,\n",
       "              0): array([-24.55130769, -27.07305062, -25.94546593, -22.24139123]),\n",
       "             (1,\n",
       "              1): array([-20.02071841, -24.26058341, -25.81634853, -15.95148157]),\n",
       "             (2,\n",
       "              0): array([-24.23455614, -26.10096866, -24.66540363, -20.02264977]),\n",
       "             (3,\n",
       "              0): array([-24.26313358, -24.76086194, -24.28828868, -19.92004444]),\n",
       "             (2,\n",
       "              1): array([-19.8247978 , -22.49612165, -24.75790919, -10.18376658]),\n",
       "             (3,\n",
       "              1): array([-19.87705918, -20.29296937, -24.05353454, -11.95566274]),\n",
       "             (3,\n",
       "              2): array([-12.14942076, -10.38361251, -19.66591027,  -3.08451284]),\n",
       "             (2,\n",
       "              2): array([-12.07459899, -16.07654911, -19.9338753 ,   9.        ]),\n",
       "             (1,\n",
       "              2): array([-10.21399539, -19.99509272, -22.24537578,  -8.31878336]),\n",
       "             (1,\n",
       "              3): array([  9.        , -15.63604868, -15.9821275 ,  -8.23851321]),\n",
       "             (0,\n",
       "              2): array([-16.01181904, -20.00628411, -24.39029657, -15.54741456]),\n",
       "             (0,\n",
       "              1): array([-22.46165023, -24.25998463, -26.92815548, -19.7880212 ]),\n",
       "             (0,\n",
       "              0): array([-26.05204922, -27.10198495, -27.06914803, -24.18440489]),\n",
       "             (2, 3): array([10., 10., 10., 10.]),\n",
       "             (0,\n",
       "              3): array([ -8.16373402, -15.71180081, -19.81797159, -15.6379898 ]),\n",
       "             (3,\n",
       "              3): array([ -3.22040525,   9.        , -12.28834163,  -2.92670032])})"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting all the values into numpy array to render\n",
    "values_matrix = np.zeros((env.size,env.size))\n",
    "for x in value:\n",
    "    values_matrix[x] = value[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<Figure size 288x288 with 1 Axes>, <AxesSubplot:>)"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.render(values_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
